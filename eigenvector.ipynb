{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from NetworkStructure import Generator\n",
    "from NetworkStructure import Discriminator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from torch.autograd import Variable\n",
    "from torch.functional import Tensor\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch\n",
    "import torchextractor as tx\n",
    "import torchvision\n",
    "%matplotlib inline\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# parameters\n",
    "image_size = 28\n",
    "img_shape = 1,28,28\n",
    "latent_dim = 100\n",
    "image_channel = 1\n",
    "batch_size = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.CenterCrop(28),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.5, 0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\"./data\", train=True, download=True,transform=data_transform)\n",
    "# test_dataset = torchvision.datasets.MNIST(\"./data\", train=False,download=True,transform=data_transform)\n",
    "# min_test = torch.utils.data.Subset(test_dataset, torch.arange(1000))\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size= batch_size,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# train_data = enumerate(train_dataloader)\n",
    "# a = next(train_data)\n",
    "# a[1][0].shape\n",
    "# enumerate = tuple(0,data) tuple(1,data) tuple(number,data)\n",
    "# iter = list[data]\n",
    "# data = list[data,label]\n",
    "train_data = iter(train_dataloader)\n",
    "# a = next(train_data)\n",
    "# a[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Discriminator(\n  (model): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Dropout2d(p=0.25, inplace=False)\n    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n    (5): Dropout2d(p=0.25, inplace=False)\n    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n    (9): Dropout2d(p=0.25, inplace=False)\n    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n    (13): Dropout2d(p=0.25, inplace=False)\n    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (adv_layer): Sequential(\n    (0): Linear(in_features=512, out_features=1, bias=True)\n    (1): Sigmoid()\n  )\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_G = \"./pre-train/checkpoint389G\"\n",
    "PATH_D = \"./pre-train/checkpoint389D\"\n",
    "checkpoint_G = torch.load(PATH_G)\n",
    "checkpoint_D = torch.load(PATH_D)\n",
    "model_G = Generator(image_size, latent_dim, image_channel)\n",
    "model_D = Discriminator(image_channel)\n",
    "model_G.load_state_dict(checkpoint_G['model_state_dict']) # print every layer name\n",
    "model_D.load_state_dict(checkpoint_D['model_state_dict'])\n",
    "model_G.eval()\n",
    "model_D.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Function using to calculate Lapula matrix\n",
    "def Lapula(feature, number, nor=False):\n",
    "    \"\"\"\n",
    "    Calculate lapula metrix\n",
    "    :param feature: input the feature\n",
    "    :param number:  the number of feature\n",
    "    :param nor:  default is False, if true Lapula matrix will be normalize\n",
    "    :return:  lapura or sys lapula\n",
    "    \"\"\"\n",
    "    # 1. Calcute the Similarity matrix and Degree matrix\n",
    "    similarity_martix = np.empty((number,number),dtype=float)\n",
    "    d_matrix = np.zeros((number,number))\n",
    "    for i in range(feature.shape[0]):\n",
    "        x1 = feature[i]\n",
    "        for r  in range(i,feature.shape[0]):\n",
    "            if i == r:\n",
    "                similarity_martix[i][r] = 0\n",
    "            else:\n",
    "                x2 = feature[r]\n",
    "                weight = torch.nn.functional.cosine_similarity(x1,x2,0).detach().numpy()\n",
    "                # print(weight)\n",
    "                if weight >= 0.7:\n",
    "                    d_matrix[i][i] += 1\n",
    "                    similarity_martix[i][r]= 1-weight\n",
    "                    similarity_martix[r][i]= 1-weight\n",
    "                else:\n",
    "                    similarity_martix[i][r]= 0\n",
    "                    similarity_martix[r][i]= 0\n",
    "    lapula = d_matrix - similarity_martix\n",
    "    if nor==True:\n",
    "         t = np.sum(d_matrix, axis= 1)\n",
    "         V = np.diag(t**(-0.5))\n",
    "         where_are_inf = np.isinf(V)\n",
    "         V[where_are_inf] = 0\n",
    "         lapula = V@lapula@V\n",
    "\n",
    "    return lapula"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1, 1, 28, 28]), torch.Size([1]))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(train_data)\n",
    "data[0].shape, data[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}